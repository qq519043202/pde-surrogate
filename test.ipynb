{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.darcy import cc1\n",
    "from models.darcy import cc2\n",
    "from models.darcy import bc\n",
    "import numpy as np\n",
    "from utils.image_gradient import SobelFilter\n",
    "from FEA_simp import ComputeTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random data\n",
    "input = np.array(np.random.random([1,1,20,40]), dtype=np.float32)\n",
    "# ComputeTarget是在FEA_simp.py中封装的计算真值的函数\n",
    "output = torch.from_numpy(np.array(ComputeTarget(input), dtype=np.float32)).to(device)\n",
    "input = torch.from_numpy(input).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data\n",
    "data = np.loadtxt(\"data/rho20x40_SIMP_Edge.txt\", dtype=np.float32)\n",
    "# [bs, 1, 20, 40]\n",
    "data = data.reshape(-1,1,40,20).transpose([0,1,3,2])\n",
    "\n",
    "data_u = np.loadtxt(\"data/dis20x40_SIMP_Edge.txt\", dtype=np.float32)\n",
    "data_s = np.loadtxt(\"data/stress20x40_SIMP_Edge.txt\", dtype=np.float32)\n",
    "\n",
    "ref_u0 = torch.from_numpy(data_u).unsqueeze(1).to(device)\n",
    "ref_uy = ref_u0[:,:,range(1,1722,2)]\n",
    "ref_ux = ref_u0[:,:,range(0,1722,2)]\n",
    "ref_s0 = torch.from_numpy(data_s).unsqueeze(1).to(device)\n",
    "ref_sx = ref_s0[:,:,range(0,2583,3)]\n",
    "ref_sy = ref_s0[:,:,range(1,2583,3)]\n",
    "ref_sxy = ref_s0[:,:,range(2,2583,3)]\n",
    "# [bs, 5, 21, 41]\n",
    "ref = torch.cat([ref_ux, ref_uy, ref_sx, ref_sy, ref_sxy],1).view(-1,5,41,21).permute(0,1,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 20, 40])\n",
      "torch.Size([16, 5, 21, 41])\n"
     ]
    }
   ],
   "source": [
    "# 取部分\n",
    "input = torch.from_numpy(data[:16])\n",
    "output = ref[:16]\n",
    "\n",
    "print(input.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 20, 40])\n"
     ]
    }
   ],
   "source": [
    "# post output\n",
    "WEIGHTS_2x2 = torch.FloatTensor( np.ones([1,1,2,2])/4 ).to(device)\n",
    "o0 = F.conv2d(output[:,[0]], WEIGHTS_2x2, stride=1, padding=0, bias=None)\n",
    "o1 = F.conv2d(output[:,[1]], WEIGHTS_2x2, stride=1, padding=0, bias=None) \n",
    "o2 = F.conv2d(output[:,[2]], WEIGHTS_2x2, stride=1, padding=0, bias=None) \n",
    "o3 = F.conv2d(output[:,[3]], WEIGHTS_2x2, stride=1, padding=0, bias=None) \n",
    "o4 = F.conv2d(output[:,[4]], WEIGHTS_2x2, stride=1, padding=0, bias=None) \n",
    "output_post = torch.cat([o0,o1,o2,o3,o4],1)\n",
    "print(output_post.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_filter = SobelFilter(64, correct=False, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.7479e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print (cc1(input, output, output_post, sobel_filter, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(31.0947, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(cc2(output_post, sobel_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2465, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "loss_boundary = bc(output, output_post)\n",
    "print(loss_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_boundary detail\n",
    "ux = output[:, [0]]\n",
    "uy = output[:, [1]]\n",
    "lu = ux[:,:,:,0]**2 + uy[:,:,:,0]**2\n",
    "sx = output[:, [2]]\n",
    "sy = output[:, [3]]\n",
    "sxy = output[:, [4]]\n",
    "lbr = (sx[:,:,:,40]-1)**2 + (sxy[:,:,:,40])**2\n",
    "lbt = (sy[:,:,0,2:-2])**2 + (sxy[:,:,0,2:-2])**2\n",
    "lbb = (sy[:,:,20,2:-2])**2 + (sxy[:,:,20,2:-2])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lu.sum([-1]).mean())\n",
    "print(lbr.sum([-1]).mean())\n",
    "print(lbt.sum([-1]).mean())\n",
    "print(lbb.sum([-1]).mean())\n",
    "# print(lbt.sum())\n",
    "# print(lbb.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([lu,lbb,lbt,lbr],2).sum([-1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc1 detail\n",
    "E = 1.0\n",
    "nu = 0.3\n",
    "# C0np = np.array()\n",
    "C0 = E/(1-nu**2)*torch.Tensor([[1,nu,0],[nu,1,0],[0,0,(1-nu)/2]]).to(device)\n",
    "pp = input.contiguous().view(input.shape[0], -1, 1, 1).to(device)\n",
    "# pp = input.permute(0,1,3,2).contiguous().view(input.shape[0], -1, 1, 1).to(device)\n",
    "C = pp**3*C0\n",
    "\n",
    "# duxdx = sobel_filter.grad_h(output[:, [0]])\n",
    "# duxdy = sobel_filter.grad_v(output[:, [0]])\n",
    "# duydx = sobel_filter.grad_h(output[:, [1]])\n",
    "# duydy = sobel_filter.grad_v(output[:, [1]])\n",
    "# d1 = duxdx\n",
    "# d2 = duydy\n",
    "# d3 = duxdy+duydx\n",
    "# du = torch.cat([d1,d2,d3],1)\n",
    "# du_post = du.view(du.shape[0],3,-1,1).permute(0,2,1,3)\n",
    "B=np.zeros([4,3,8],dtype=np.float32)\n",
    "B[0,:,:]=np.array([ [-1,  0, 1, 0, 0, 0, 0, 0],\n",
    "                    [0, -1, 0, 0, 0, 0, 0, 1],\n",
    "                    [-1, -1, 0, 1, 0, 0, 1, 0] ])\n",
    "B[1,:,:]=np.array([ [-1,  0,  1,  0, 0, 0, 0, 0],\n",
    "                    [0,  0,  0, -1, 0, 1, 0, 0],\n",
    "                    [0, -1, -1,  1, 1, 0, 0, 0] ])\n",
    "B[2,:,:]=np.array([ [0, 0,  0,  0, 1, 0, -1,  0],\n",
    "                    [0, 0,  0, -1, 0, 1,  0,  0],\n",
    "                    [0, 0, -1,  0, 1, 1,  0, -1] ])\n",
    "B[3,:,:]=np.array([ [0,  0, 0, 0, 1, 0, -1,  0],\n",
    "                    [0, -1, 0, 0, 0, 0,  0,  1],\n",
    "                    [-1,  0, 0, 0, 0, 1,  1, -1] ])\n",
    "B = torch.from_numpy(B).to(device)\n",
    "\n",
    "B0 = torch.Tensor([[-0.5,0,-0.5],[0,-0.5,-0.5],[0.5,0,-0.5],\\\n",
    "    [0,-0.5,0.5],[0.5,0,0.5] ,[0,0.5,0.5],[-0.5,0,0.5],[0,-0.5,-0.5]]).to(device)\n",
    "B0T = B0.transpose(0,1)\n",
    "ux = output[:,[0]]\n",
    "uy = output[:,[1]]\n",
    "\n",
    "# k1 = torch.FloatTensor( np.array([[[[-0.5,0.5],[-0.5,0.5]]]]) ).to(device)\n",
    "# k2 = torch.FloatTensor( np.array([[[[-0.5,-0.5],[-0.5,0.5]]]]) ).to(device)\n",
    "# k31 = torch.FloatTensor( np.array([[[[-0.5,-0.5],[0.5,0.5]]]]) ).to(device)\n",
    "# k32 = torch.FloatTensor( np.array([[[[-0.5,0.5],[-0.5,0.5]]]]) ).to(device)\n",
    "# ux1 = F.conv2d(ux, k1, stride=1, padding=0, bias=None)\n",
    "# uy1 = F.conv2d(uy, k2, stride=1, padding=0, bias=None)\n",
    "# ux2 = F.conv2d(ux, k31, stride=1, padding=0, bias=None)\n",
    "# uy2 = F.conv2d(uy, k32, stride=1, padding=0, bias=None)\n",
    "# utest = torch.cat([ux1, uy1, ux2+uy2], 1)\n",
    "\n",
    "unfold = nn.Unfold(kernel_size=(2, 2))\n",
    "# [bs, 4, w*h]\n",
    "uex = unfold(ux)\n",
    "uey = unfold(uy)\n",
    "ue_not = torch.cat([uex, uey], 1).permute([0,2,1])\n",
    "ue = ue_not[:,:,[0,4,1,5,3,7,2,6]].unsqueeze(3)\n",
    "\n",
    "\n",
    "\n",
    "# sig = output_post[:, [2,3,4]]\n",
    "# sig_post = sig.view(sig.shape[0],3,-1,1).permute(0,2,1,3)\n",
    "du0 = torch.matmul(C0@B[0,:,:],ue)\n",
    "du1 = torch.matmul(C0@B[1,:,:],ue)\n",
    "du2 = torch.matmul(C0@B[2,:,:],ue)\n",
    "du3 = torch.matmul(C0@B[3,:,:],ue)\n",
    "du0t = du0.permute([0,2,1,3]).contiguous().view(-1,3,20,40)\n",
    "du1t = du1.permute([0,2,1,3]).contiguous().view(-1,3,20,40)\n",
    "du2t = du2.permute([0,2,1,3]).contiguous().view(-1,3,20,40)\n",
    "du3t = du3.permute([0,2,1,3]).contiguous().view(-1,3,20,40)\n",
    "ones = torch.ones_like(du0t)\n",
    "\n",
    "masks =torch.zeros([du0.shape[0],3,21,41]).to(device)\n",
    "result =torch.zeros([du0.shape[0],3,21,41]).to(device)\n",
    "\n",
    "penal=3\n",
    "Dp=torch.zeros([du0.shape[0],3,20,40]).to(device)\n",
    "Dp[0,0,:,:]=input**penal\n",
    "Dp[0,1,:,:]=input**penal\n",
    "Dp[0,2,:,:]=input**penal\n",
    "\n",
    "result[:,:,:20,:40] = du0t*Dp\n",
    "result[:,:,:20,1:] = result[:,:,:20,1:]+du1t*Dp\n",
    "result[:,:,1:,:40] = result[:,:,1:,:40]+du3t*Dp\n",
    "result[:,:,1:,1:] = result[:,:,1:,1:]+du2t*Dp\n",
    "\n",
    "\n",
    "\n",
    "masks[:,:,:20,:40] += ones\n",
    "masks[:,:,:20,1:] += ones\n",
    "masks[:,:,1:,:40] += ones\n",
    "masks[:,:,1:,1:] += ones\n",
    "lp1 = (result / masks) - output[:, [2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ue[0,0,:,0])\n",
    "ue[0,1,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(du0t.shape)\n",
    "du0t[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lp1.shape)\n",
    "print((lp1**2).sum([1,2,3]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxy[0,0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(masks.shape)\n",
    "masks[0,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc2 loss detail\n",
    "dsxdx = sobel_filter.grad_h(output_post[:, [2]])\n",
    "dsydy = sobel_filter.grad_v(output_post[:, [3]])\n",
    "dsxydx = sobel_filter.grad_h(output_post[:, [4]])\n",
    "dsxydy = sobel_filter.grad_v(output_post[:, [4]])\n",
    "\n",
    "ds = torch.cat([dsxdx+dsxydy, dsydy+dsxydx],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 20, 40])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.3706, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print((ds ** 2).sum([1,2,3]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.7309e-01, -9.8053e-02, -7.7725e-02, -5.3725e-02, -3.4291e-02,\n",
       "          -2.0941e-02, -1.2106e-02, -6.2938e-03, -2.4844e-03,  1.4901e-08,\n",
       "           1.6156e-03,  2.6500e-03,  3.2969e-03,  3.6719e-03,  3.8469e-03,\n",
       "           3.8843e-03,  3.8281e-03,  3.6969e-03,  3.5125e-03,  3.3093e-03,\n",
       "           3.0781e-03,  2.8157e-03,  2.5468e-03,  2.2875e-03,  2.0344e-03,\n",
       "           1.7906e-03,  1.5719e-03,  1.3594e-03,  1.1531e-03,  9.8120e-04,\n",
       "           8.3748e-04,  6.9065e-04,  5.5625e-04,  4.5626e-04,  3.7191e-04,\n",
       "           2.9064e-04,  1.9682e-04,  1.0624e-04,  5.9374e-05, -3.7496e-01],\n",
       "         [ 5.7779e-01, -3.6600e-02, -4.0275e-02, -4.2078e-02, -3.5528e-02,\n",
       "          -2.6706e-02, -1.8759e-02, -1.2434e-02, -7.6781e-03, -4.1750e-03,\n",
       "          -1.6031e-03,  2.5000e-04,  1.5594e-03,  2.4750e-03,  3.0875e-03,\n",
       "           3.4500e-03,  3.6343e-03,  3.6844e-03,  3.6250e-03,  3.5094e-03,\n",
       "           3.3344e-03,  3.0938e-03,  2.8281e-03,  2.5719e-03,  2.3188e-03,\n",
       "           2.0531e-03,  1.8031e-03,  1.5781e-03,  1.3594e-03,  1.1531e-03,\n",
       "           9.8123e-04,  8.2190e-04,  6.6876e-04,  5.4687e-04,  4.5314e-04,\n",
       "           3.7190e-04,  2.7184e-04,  1.6563e-04,  1.0312e-04, -4.9993e-01],\n",
       "         [ 5.1873e-01,  2.7144e-02,  1.6200e-02, -3.0719e-03, -1.4066e-02,\n",
       "          -1.7272e-02, -1.6300e-02, -1.3697e-02, -1.0750e-02, -7.9812e-03,\n",
       "          -5.5563e-03, -3.5469e-03, -1.9437e-03, -6.8127e-04,  2.8749e-04,\n",
       "           9.8125e-04,  1.4687e-03,  1.7969e-03,  1.9813e-03,  2.0719e-03,\n",
       "           2.0781e-03,  2.0031e-03,  1.8843e-03,  1.7625e-03,  1.6375e-03,\n",
       "           1.4750e-03,  1.3000e-03,  1.1562e-03,  1.0219e-03,  8.7187e-04,\n",
       "           7.3754e-04,  6.3125e-04,  5.3434e-04,  4.3752e-04,  3.6250e-04,\n",
       "           3.1248e-04,  2.4687e-04,  1.7189e-04,  1.1876e-04, -4.9993e-01],\n",
       "         [ 4.8754e-01,  2.8769e-02,  2.9006e-02,  1.7591e-02,  5.6937e-03,\n",
       "          -2.7781e-03, -7.2282e-03, -8.7907e-03, -8.6687e-03, -7.7093e-03,\n",
       "          -6.3938e-03, -5.0094e-03, -3.7125e-03, -2.5813e-03, -1.6375e-03,\n",
       "          -8.8125e-04, -2.9065e-04,  1.4998e-04,  4.6563e-04,  6.9064e-04,\n",
       "           8.2503e-04,  8.8438e-04,  8.9372e-04,  8.8126e-04,  8.5939e-04,\n",
       "           8.0624e-04,  7.3124e-04,  6.5938e-04,  5.9374e-04,  5.2500e-04,\n",
       "           4.4692e-04,  3.8437e-04,  3.4371e-04,  2.8441e-04,  2.3439e-04,\n",
       "           2.1247e-04,  1.7186e-04,  1.3126e-04,  1.0626e-04, -4.9993e-01],\n",
       "         [ 4.7255e-01,  2.2712e-02,  2.6316e-02,  2.1688e-02,  1.4988e-02,\n",
       "           7.8781e-03,  2.1312e-03, -1.6375e-03, -3.6875e-03, -4.5438e-03,\n",
       "          -4.6250e-03, -4.2531e-03, -3.6656e-03, -3.0344e-03, -2.4313e-03,\n",
       "          -1.8719e-03, -1.3937e-03, -1.0187e-03, -7.0939e-04, -4.4997e-04,\n",
       "          -2.5939e-04, -1.2190e-04, -2.8133e-05,  2.8096e-05,  7.1920e-05,\n",
       "           1.1254e-04,  1.4060e-04,  1.4063e-04,  1.3125e-04,  1.3746e-04,\n",
       "           1.3125e-04,  1.1249e-04,  1.0627e-04,  9.0666e-05,  8.4378e-05,\n",
       "           9.3728e-05,  7.1853e-05,  5.9381e-05,  6.8747e-05, -4.9995e-01],\n",
       "         [ 4.6466e-01,  1.7944e-02,  2.2216e-02,  2.0313e-02,  1.7034e-02,\n",
       "           1.2725e-02,  8.2062e-03,  4.3406e-03,  1.4625e-03, -4.8752e-04,\n",
       "          -1.6501e-03, -2.2281e-03, -2.4374e-03, -2.4437e-03, -2.3250e-03,\n",
       "          -2.1219e-03, -1.9000e-03, -1.7000e-03, -1.5032e-03, -1.3062e-03,\n",
       "          -1.1281e-03, -9.6565e-04, -8.2815e-04, -7.2503e-04, -6.3746e-04,\n",
       "          -5.3745e-04, -4.3128e-04, -3.5938e-04, -3.1248e-04, -2.5317e-04,\n",
       "          -1.9689e-04, -1.5938e-04, -1.3121e-04, -1.0934e-04, -7.4990e-05,\n",
       "          -3.7506e-05, -3.7536e-05, -2.5004e-05,  1.2502e-05, -4.9999e-01],\n",
       "         [ 4.6032e-01,  1.4950e-02,  1.8963e-02,  1.8084e-02,  1.6466e-02,\n",
       "           1.4072e-02,  1.1144e-02,  8.1406e-03,  5.4094e-03,  3.1375e-03,\n",
       "           1.4124e-03,  1.6880e-04, -7.0934e-04, -1.3031e-03, -1.6719e-03,\n",
       "          -1.8751e-03, -1.9657e-03, -1.9875e-03, -1.9625e-03, -1.8906e-03,\n",
       "          -1.7718e-03, -1.6250e-03, -1.4813e-03, -1.3438e-03, -1.2188e-03,\n",
       "          -1.0906e-03, -9.3749e-04, -8.0311e-04, -7.0305e-04, -6.0628e-04,\n",
       "          -5.0943e-04, -4.1871e-04, -3.4682e-04, -2.9066e-04, -2.2817e-04,\n",
       "          -1.7184e-04, -1.4682e-04, -1.0628e-04, -4.6909e-05, -5.0002e-01],\n",
       "         [ 4.5782e-01,  1.3169e-02,  1.6825e-02,  1.6247e-02,  1.5341e-02,\n",
       "           1.4003e-02,  1.2225e-02,  1.0134e-02,  7.9157e-03,  5.7906e-03,\n",
       "           3.9156e-03,  2.3094e-03,  9.7814e-04, -5.6267e-05, -8.3122e-04,\n",
       "          -1.4032e-03, -1.7906e-03, -2.0312e-03, -2.1781e-03, -2.2407e-03,\n",
       "          -2.2062e-03, -2.0968e-03, -1.9657e-03, -1.8219e-03, -1.6688e-03,\n",
       "          -1.5157e-03, -1.3406e-03, -1.1625e-03, -1.0187e-03, -8.9066e-04,\n",
       "          -7.6568e-04, -6.4372e-04, -5.3121e-04, -4.3754e-04, -3.5632e-04,\n",
       "          -2.9370e-04, -2.4365e-04, -1.7190e-04, -1.0003e-04, -5.0006e-01],\n",
       "         [ 4.5643e-01,  1.2166e-02,  1.5562e-02,  1.5053e-02,  1.4419e-02,\n",
       "           1.3597e-02,  1.2478e-02,  1.1012e-02,  9.2813e-03,  7.4345e-03,\n",
       "           5.5969e-03,  3.8468e-03,  2.2688e-03,  9.5625e-04, -9.6872e-05,\n",
       "          -9.4067e-04, -1.5625e-03, -1.9781e-03, -2.2532e-03, -2.4156e-03,\n",
       "          -2.4593e-03, -2.3968e-03, -2.2813e-03, -2.1469e-03, -1.9812e-03,\n",
       "          -1.8000e-03, -1.6157e-03, -1.4218e-03, -1.2468e-03, -1.0875e-03,\n",
       "          -9.4064e-04, -8.0311e-04, -6.6252e-04, -5.4063e-04, -4.5002e-04,\n",
       "          -3.8441e-04, -3.1251e-04, -2.2185e-04, -1.4682e-04, -5.0008e-01],\n",
       "         [ 4.5580e-01,  1.1709e-02,  1.4978e-02,  1.4478e-02,  1.3934e-02,\n",
       "           1.3316e-02,  1.2478e-02,  1.1316e-02,  9.8657e-03,  8.2032e-03,\n",
       "           6.4219e-03,  4.6374e-03,  2.9594e-03,  1.5156e-03,  3.2499e-04,\n",
       "          -6.6254e-04, -1.4156e-03, -1.9281e-03, -2.2719e-03, -2.4844e-03,\n",
       "          -2.5656e-03, -2.5406e-03, -2.4438e-03, -2.3094e-03, -2.1375e-03,\n",
       "          -1.9407e-03, -1.7532e-03, -1.5624e-03, -1.3687e-03, -1.1875e-03,\n",
       "          -1.0281e-03, -8.8124e-04, -7.3124e-04, -5.9690e-04, -4.9999e-04,\n",
       "          -4.2816e-04, -3.4381e-04, -2.5310e-04, -1.7805e-04, -5.0010e-01],\n",
       "         [ 4.5580e-01,  1.1709e-02,  1.4978e-02,  1.4478e-02,  1.3934e-02,\n",
       "           1.3316e-02,  1.2478e-02,  1.1316e-02,  9.8656e-03,  8.2031e-03,\n",
       "           6.4219e-03,  4.6374e-03,  2.9594e-03,  1.5156e-03,  3.2499e-04,\n",
       "          -6.6249e-04, -1.4156e-03, -1.9281e-03, -2.2720e-03, -2.4843e-03,\n",
       "          -2.5656e-03, -2.5406e-03, -2.4438e-03, -2.3094e-03, -2.1375e-03,\n",
       "          -1.9407e-03, -1.7532e-03, -1.5625e-03, -1.3687e-03, -1.1875e-03,\n",
       "          -1.0282e-03, -8.8122e-04, -7.3120e-04, -5.9690e-04, -4.9995e-04,\n",
       "          -4.2816e-04, -3.4386e-04, -2.5310e-04, -1.7805e-04, -5.0010e-01],\n",
       "         [ 4.5643e-01,  1.2166e-02,  1.5562e-02,  1.5053e-02,  1.4419e-02,\n",
       "           1.3597e-02,  1.2478e-02,  1.1013e-02,  9.2812e-03,  7.4344e-03,\n",
       "           5.5969e-03,  3.8468e-03,  2.2688e-03,  9.5627e-04, -9.6902e-05,\n",
       "          -9.4064e-04, -1.5625e-03, -1.9781e-03, -2.2532e-03, -2.4156e-03,\n",
       "          -2.4593e-03, -2.3969e-03, -2.2813e-03, -2.1469e-03, -1.9812e-03,\n",
       "          -1.8000e-03, -1.6156e-03, -1.4218e-03, -1.2469e-03, -1.0875e-03,\n",
       "          -9.4068e-04, -8.0308e-04, -6.6246e-04, -5.4063e-04, -4.4994e-04,\n",
       "          -3.8442e-04, -3.1260e-04, -2.2185e-04, -1.4681e-04, -5.0008e-01],\n",
       "         [ 4.5782e-01,  1.3169e-02,  1.6825e-02,  1.6247e-02,  1.5341e-02,\n",
       "           1.4003e-02,  1.2225e-02,  1.0134e-02,  7.9156e-03,  5.7906e-03,\n",
       "           3.9156e-03,  2.3094e-03,  9.7817e-04, -5.6252e-05, -8.3134e-04,\n",
       "          -1.4032e-03, -1.7906e-03, -2.0312e-03, -2.1781e-03, -2.2406e-03,\n",
       "          -2.2063e-03, -2.0968e-03, -1.9657e-03, -1.8219e-03, -1.6687e-03,\n",
       "          -1.5157e-03, -1.3406e-03, -1.1625e-03, -1.0187e-03, -8.9066e-04,\n",
       "          -7.6570e-04, -6.4372e-04, -5.3120e-04, -4.3753e-04, -3.5624e-04,\n",
       "          -2.9372e-04, -2.4378e-04, -1.7190e-04, -9.9972e-05, -5.0006e-01],\n",
       "         [ 4.6032e-01,  1.4950e-02,  1.8963e-02,  1.8084e-02,  1.6466e-02,\n",
       "           1.4072e-02,  1.1144e-02,  8.1406e-03,  5.4094e-03,  3.1375e-03,\n",
       "           1.4125e-03,  1.6882e-04, -7.0935e-04, -1.3031e-03, -1.6720e-03,\n",
       "          -1.8750e-03, -1.9656e-03, -1.9875e-03, -1.9625e-03, -1.8906e-03,\n",
       "          -1.7719e-03, -1.6250e-03, -1.4813e-03, -1.3437e-03, -1.2187e-03,\n",
       "          -1.0906e-03, -9.3746e-04, -8.0313e-04, -7.0308e-04, -6.0628e-04,\n",
       "          -5.0943e-04, -4.1871e-04, -3.4682e-04, -2.9066e-04, -2.2812e-04,\n",
       "          -1.7186e-04, -1.4691e-04, -1.0626e-04, -4.6864e-05, -5.0002e-01],\n",
       "         [ 4.6466e-01,  1.7944e-02,  2.2216e-02,  2.0313e-02,  1.7034e-02,\n",
       "           1.2725e-02,  8.2063e-03,  4.3406e-03,  1.4625e-03, -4.8746e-04,\n",
       "          -1.6501e-03, -2.2281e-03, -2.4374e-03, -2.4438e-03, -2.3250e-03,\n",
       "          -2.1219e-03, -1.9000e-03, -1.7000e-03, -1.5032e-03, -1.3062e-03,\n",
       "          -1.1281e-03, -9.6565e-04, -8.2816e-04, -7.2503e-04, -6.3744e-04,\n",
       "          -5.3745e-04, -4.3127e-04, -3.5938e-04, -3.1249e-04, -2.5315e-04,\n",
       "          -1.9689e-04, -1.5935e-04, -1.3122e-04, -1.0939e-04, -7.4983e-05,\n",
       "          -3.7514e-05, -3.7536e-05, -2.4997e-05,  1.2502e-05, -4.9999e-01],\n",
       "         [ 4.7255e-01,  2.2712e-02,  2.6316e-02,  2.1688e-02,  1.4988e-02,\n",
       "           7.8781e-03,  2.1313e-03, -1.6375e-03, -3.6875e-03, -4.5437e-03,\n",
       "          -4.6251e-03, -4.2531e-03, -3.6656e-03, -3.0344e-03, -2.4313e-03,\n",
       "          -1.8719e-03, -1.3937e-03, -1.0187e-03, -7.0944e-04, -4.4997e-04,\n",
       "          -2.5933e-04, -1.2189e-04, -2.8156e-05,  2.8089e-05,  7.1935e-05,\n",
       "           1.1254e-04,  1.4058e-04,  1.4063e-04,  1.3127e-04,  1.3749e-04,\n",
       "           1.3125e-04,  1.1250e-04,  1.0627e-04,  9.0614e-05,  8.4378e-05,\n",
       "           9.3751e-05,  7.1853e-05,  5.9366e-05,  6.8747e-05, -4.9995e-01],\n",
       "         [ 4.8754e-01,  2.8769e-02,  2.9006e-02,  1.7591e-02,  5.6937e-03,\n",
       "          -2.7781e-03, -7.2282e-03, -8.7907e-03, -8.6687e-03, -7.7093e-03,\n",
       "          -6.3938e-03, -5.0094e-03, -3.7125e-03, -2.5813e-03, -1.6375e-03,\n",
       "          -8.8125e-04, -2.9065e-04,  1.5001e-04,  4.6563e-04,  6.9062e-04,\n",
       "           8.2503e-04,  8.8441e-04,  8.9371e-04,  8.8123e-04,  8.5939e-04,\n",
       "           8.0626e-04,  7.3124e-04,  6.5936e-04,  5.9377e-04,  5.2501e-04,\n",
       "           4.4689e-04,  3.8436e-04,  3.4372e-04,  2.8436e-04,  2.3437e-04,\n",
       "           2.1253e-04,  1.7187e-04,  1.3126e-04,  1.0626e-04, -4.9993e-01],\n",
       "         [ 5.1873e-01,  2.7144e-02,  1.6200e-02, -3.0719e-03, -1.4066e-02,\n",
       "          -1.7272e-02, -1.6300e-02, -1.3697e-02, -1.0750e-02, -7.9812e-03,\n",
       "          -5.5563e-03, -3.5469e-03, -1.9437e-03, -6.8127e-04,  2.8749e-04,\n",
       "           9.8125e-04,  1.4687e-03,  1.7969e-03,  1.9813e-03,  2.0719e-03,\n",
       "           2.0781e-03,  2.0031e-03,  1.8844e-03,  1.7625e-03,  1.6375e-03,\n",
       "           1.4750e-03,  1.3000e-03,  1.1562e-03,  1.0219e-03,  8.7188e-04,\n",
       "           7.3750e-04,  6.3124e-04,  5.3434e-04,  4.3748e-04,  3.6251e-04,\n",
       "           3.1253e-04,  2.4687e-04,  1.7188e-04,  1.1876e-04, -4.9993e-01],\n",
       "         [ 5.7779e-01, -3.6600e-02, -4.0275e-02, -4.2078e-02, -3.5528e-02,\n",
       "          -2.6706e-02, -1.8759e-02, -1.2434e-02, -7.6781e-03, -4.1750e-03,\n",
       "          -1.6031e-03,  2.4999e-04,  1.5594e-03,  2.4750e-03,  3.0875e-03,\n",
       "           3.4500e-03,  3.6343e-03,  3.6844e-03,  3.6250e-03,  3.5093e-03,\n",
       "           3.3344e-03,  3.0938e-03,  2.8281e-03,  2.5719e-03,  2.3187e-03,\n",
       "           2.0531e-03,  1.8031e-03,  1.5781e-03,  1.3594e-03,  1.1531e-03,\n",
       "           9.8122e-04,  8.2190e-04,  6.6876e-04,  5.4690e-04,  4.5316e-04,\n",
       "           3.7187e-04,  2.7185e-04,  1.6563e-04,  1.0310e-04, -4.9993e-01],\n",
       "         [ 4.7309e-01, -9.8053e-02, -7.7725e-02, -5.3725e-02, -3.4291e-02,\n",
       "          -2.0941e-02, -1.2106e-02, -6.2938e-03, -2.4844e-03,  1.4901e-08,\n",
       "           1.6156e-03,  2.6500e-03,  3.2969e-03,  3.6719e-03,  3.8469e-03,\n",
       "           3.8843e-03,  3.8281e-03,  3.6969e-03,  3.5125e-03,  3.3093e-03,\n",
       "           3.0781e-03,  2.8156e-03,  2.5469e-03,  2.2875e-03,  2.0344e-03,\n",
       "           1.7906e-03,  1.5719e-03,  1.3594e-03,  1.1531e-03,  9.8123e-04,\n",
       "           8.3749e-04,  6.9065e-04,  5.5625e-04,  4.5627e-04,  3.7190e-04,\n",
       "           2.9062e-04,  1.9686e-04,  1.0625e-04,  5.9344e-05, -3.7496e-01]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsxdx.mean([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
